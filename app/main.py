"""
Main FastAPI application for the Input Preparation Module.

Provides endpoints for text and media preparation with HMAC verification.
"""

import time
import os
from typing import Optional, List
from fastapi import FastAPI, File, UploadFile, Form, HTTPException, status, Request
from fastapi.responses import JSONResponse, HTMLResponse
from fastapi.middleware.cors import CORSMiddleware
from fastapi.staticfiles import StaticFiles
from pydantic import BaseModel

from app.config import settings
from app.models.schemas import PreparedInput, HealthResponse, InputRequest, MediaRequest
from app.utils.logger import setup_logging, get_logger, RequestLogger
from app.services.input_parser import parse_and_validate, validate_request
from app.services.file_extractor import (
    extract_file_text,
    validate_file,
    check_library_availability
)
from app.services.rag_handler import process_rag_data
from app.services.text_normalizer import normalize_text
from app.services.media_processor import (
    process_media,
    check_image_library_availability
)
from app.services.token_processor import calculate_tokens_and_stats
from app.services.payload_packager import (
    package_payload,
    validate_payload,
    summarize_payload,
    create_error_response
)
from app.services.llm_service import generate_response, check_model_availability
from app.services.output_saver import get_output_saver

# Setup logging
setup_logging()
logger = get_logger(__name__)

# Create FastAPI app
app = FastAPI(
    title=settings.API_TITLE,
    version=settings.API_VERSION,
    description=(
        "Input Preparation Module for LLM-Protect pipeline. "
        "Handles file extraction, RAG data processing, text normalization, "
        "and HMAC verification for secure LLM input preparation."
    ),
    docs_url="/docs",
    redoc_url="/redoc"
)

# Add CORS middleware
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # Configure appropriately for production
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Mount static files (for web interface)
try:
    from pathlib import Path
    static_path = Path(__file__).parent / "static"
    static_path.mkdir(exist_ok=True)
    app.mount("/static", StaticFiles(directory=str(static_path)), name="static")
except Exception as e:
    logger.warning(f"Could not mount static files: {e}")


# Pydantic models for LLM endpoints
class GenerateRequest(BaseModel):
    """Request model for LLM generation."""
    prepared_input: PreparedInput
    max_new_tokens: int = 512
    temperature: float = 0.7
    top_p: float = 0.9
    do_sample: bool = True


class GenerateResponse(BaseModel):
    """Response model for LLM generation."""
    success: bool
    generated_text: str
    input_tokens: int
    output_tokens: int
    total_time_ms: float
    model: str = "gemma-2b"
    error: Optional[str] = None
    preparation_metadata: Optional[dict] = None


@app.on_event("startup")
async def startup_event():
    """Initialize application on startup."""
    logger.info("=" * 60)
    logger.info(f"Starting {settings.API_TITLE} v{settings.API_VERSION}")
    logger.info(f"Upload directory: {settings.UPLOAD_DIR}")
    logger.info(f"Max file size: {settings.MAX_FILE_SIZE_MB}MB")
    logger.info(f"Allowed extensions: {settings.ALLOWED_EXTENSIONS}")
    
    # Check library availability
    file_libs = check_library_availability()
    logger.info(f"File extraction libraries: {file_libs}")
    logger.info(f"Image processing: {'enabled' if check_image_library_availability() else 'disabled'}")
    logger.info("=" * 60)


@app.get("/health", response_model=HealthResponse)
async def health_check():
    """
    Health check endpoint.
    
    Returns service status and library availability.
    """
    file_libs = check_library_availability()
    image_available = check_image_library_availability()
    
    all_libs = {
        **file_libs,
        "image": image_available,
    }
    
    # Determine status
    critical_missing = not all([file_libs["txt"], file_libs["md"]])
    
    if critical_missing:
        status_msg = "degraded"
        message = "Some critical libraries are missing"
    else:
        status_msg = "healthy"
        message = "All systems operational"
    
    return HealthResponse(
        status=status_msg,
        version=settings.API_VERSION,
        timestamp=time.strftime("%Y-%m-%dT%H:%M:%SZ", time.gmtime()),
        libraries=all_libs,
        message=message
    )


@app.post(
    f"{settings.API_PREFIX}/prepare-text",
    response_model=PreparedInput,
    status_code=status.HTTP_200_OK,
    summary="Prepare text input for Layer 0",
    description=(
        "Accepts text input with optional file uploads and external data. "
        "Processes through normalization, RAG handling, and HMAC signing. "
        "Returns structured data ready for Layer 0 (text processing)."
    )
)
async def prepare_text_input(
    user_prompt: str = Form(..., description="User's input text"),
    external_data: Optional[str] = Form(None, description="JSON array of external data strings"),
    file: Optional[UploadFile] = File(None, description="Optional file upload (TXT/MD/PDF/DOCX)"),
    file_path: Optional[str] = Form(None, description="Optional path to file on server"),
    retrieve_from_vector_db: bool = Form(False, description="Retrieve from vector database")
):
    """
    Prepare text input with comprehensive processing.
    
    Steps:
    1. Parse and validate input
    2. Extract text from file (if provided)
    3. Process RAG/external data
    4. Normalize text
    5. Calculate tokens and stats
    6. Package final payload with HMAC signatures
    """
    start_time = time.time()
    step_times = {}
    
    # Parse external_data if it's a JSON string
    import json
    external_data_list = None
    if external_data:
        try:
            external_data_list = json.loads(external_data)
        except json.JSONDecodeError:
            # Treat as single string
            external_data_list = [external_data]
    
    try:
        # Step 1: Parse and validate
        step_start = time.time()
        
        # Validate request
        valid, error = validate_request(user_prompt)
        if not valid:
            raise HTTPException(status_code=400, detail=error)
        
        # Handle file upload
        temp_file_path = None
        if file:
            # Save uploaded file
            filename = file.filename
            temp_file_path = str(settings.get_file_path(filename))
            
            with open(temp_file_path, "wb") as f:
                content = await file.read()
                f.write(content)
            
            logger.info(f"File uploaded: {filename} ({len(content)} bytes)")
            file_path = temp_file_path
        
        parsed = parse_and_validate(
            user_prompt=user_prompt,
            file_path=file_path,
            external_data=external_data_list
        )
        
        request_id = parsed["request_id"]
        step_times["parse_validate"] = (time.time() - step_start) * 1000
        
        # DETAILED LOG: Show parsed input
        logger.info(f"[{request_id}] ===== STEP 1: PARSED INPUT =====")
        logger.info(f"[{request_id}] Raw user text: {parsed['raw_user'][:100]}..." if len(parsed['raw_user']) > 100 else f"[{request_id}] Raw user text: {parsed['raw_user']}")
        logger.info(f"[{request_id}] External data items: {len(parsed['raw_external'])}")
        if parsed['raw_external']:
            for i, ext in enumerate(parsed['raw_external'][:3]):  # Show first 3
                logger.info(f"[{request_id}]   External[{i}]: {ext[:80]}..." if len(ext) > 80 else f"[{request_id}]   External[{i}]: {ext}")
        logger.info(f"[{request_id}] File provided: {parsed['raw_file'] or 'None'}")
        logger.info(f"[{request_id}] Validation: {parsed['validation']}")
        
        with RequestLogger(request_id, logger) as req_logger:
            # Step 2: Extract file text (if file provided)
            step_start = time.time()
            file_chunks = []
            file_info = None
            
            if parsed["raw_file"] and parsed["validation"]["file_valid"]:
                valid_file, error = validate_file(parsed["raw_file"])
                if valid_file:
                    try:
                        file_chunks, file_info = extract_file_text(parsed["raw_file"])
                        req_logger.log_step("file_extraction", (time.time() - step_start) * 1000)
                        
                        # DETAILED LOG: Show file extraction results
                        logger.info(f"[{request_id}] ===== STEP 2: FILE EXTRACTION =====")
                        logger.info(f"[{request_id}] File: {file_info.original_path}")
                        logger.info(f"[{request_id}] Type: {file_info.type}, Hash: {file_info.hash[:16]}...")
                        logger.info(f"[{request_id}] Extraction success: {file_info.extraction_success}")
                        logger.info(f"[{request_id}] Chunks created: {file_info.chunk_count}")
                        if file_chunks:
                            logger.info(f"[{request_id}] First chunk preview: {file_chunks[0].content[:100]}...")
                            logger.info(f"[{request_id}] Total extracted chars: {sum(len(c.content) for c in file_chunks)}")
                    except Exception as e:
                        logger.error(f"File extraction failed: {e}")
                        # Continue without file data
                else:
                    logger.warning(f"File validation failed: {error}")
            else:
                logger.info(f"[{request_id}] ===== STEP 2: FILE EXTRACTION =====")
                logger.info(f"[{request_id}] No file provided")
            
            step_times["file_extraction"] = (time.time() - step_start) * 1000
            
            # Step 3: Process RAG data
            step_start = time.time()
            external_chunks, hmacs, rag_enabled = process_rag_data(
                user_prompt=parsed["raw_user"],
                external_data=parsed["raw_external"],
                file_chunks=file_chunks,
                retrieve_from_db=retrieve_from_vector_db
            )
            step_times["rag_processing"] = (time.time() - step_start) * 1000
            req_logger.log_step("rag_processing", step_times["rag_processing"])
            
            # DETAILED LOG: Show RAG processing
            logger.info(f"[{request_id}] ===== STEP 3: RAG DATA PROCESSING =====")
            logger.info(f"[{request_id}] RAG enabled: {rag_enabled}")
            logger.info(f"[{request_id}] External chunks processed: {len(external_chunks)}")
            logger.info(f"[{request_id}] HMAC signatures generated: {len(hmacs)}")
            if external_chunks:
                for i, (chunk, hmac) in enumerate(list(zip(external_chunks, hmacs))[:3]):  # Show first 3
                    logger.info(f"[{request_id}]   Chunk[{i}]: {chunk[:80]}...")
                    logger.info(f"[{request_id}]   HMAC[{i}]: {hmac[:16]}...")
            logger.info(f"[{request_id}] Delimiter format: [EXTERNAL]content[/EXTERNAL]")
            
            # Step 4: Normalize text
            step_start = time.time()
            normalized_user, user_emojis, user_emoji_descs = normalize_text(
                parsed["raw_user"],
                preserve_emojis=True
            )
            
            # Normalize external chunks (already have delimiters)
            # The chunks are already delimited, so we just use them as-is
            normalized_external = external_chunks
            
            step_times["normalization"] = (time.time() - step_start) * 1000
            req_logger.log_step("normalization", step_times["normalization"])
            
            # DETAILED LOG: Show normalization
            logger.info(f"[{request_id}] ===== STEP 4: TEXT NORMALIZATION =====")
            logger.info(f"[{request_id}] Original user text length: {len(parsed['raw_user'])}")
            logger.info(f"[{request_id}] Normalized user text length: {len(normalized_user)}")
            logger.info(f"[{request_id}] Normalized text: {normalized_user[:100]}..." if len(normalized_user) > 100 else f"[{request_id}] Normalized text: {normalized_user}")
            logger.info(f"[{request_id}] Emojis found: {len(user_emojis)}")
            if user_emojis:
                logger.info(f"[{request_id}] Emoji types: {user_emojis}")
                logger.info(f"[{request_id}] Emoji descriptions: {user_emoji_descs}")
            logger.info(f"[{request_id}] Emojis preserved in text: YES")
            
            # Step 5: Process media (emojis only for text endpoint)
            step_start = time.time()
            image_dict, emoji_summary = process_media(
                emojis=user_emojis,
                emoji_descriptions=user_emoji_descs
            )
            step_times["media_processing"] = (time.time() - step_start) * 1000
            
            # Step 6: Calculate tokens and stats
            step_start = time.time()
            
            # Calculate total extracted chars from file
            extracted_total_chars = sum(len(chunk.content) for chunk in file_chunks)
            
            stats = calculate_tokens_and_stats(
                user_text=normalized_user,
                external_chunks=normalized_external,
                file_chunks_count=len(file_chunks),
                extracted_total_chars=extracted_total_chars
            )
            step_times["token_calculation"] = (time.time() - step_start) * 1000
            req_logger.log_step("token_calculation", step_times["token_calculation"])
            
            # DETAILED LOG: Show token stats
            logger.info(f"[{request_id}] ===== STEP 5: TOKEN & STATS CALCULATION =====")
            logger.info(f"[{request_id}] Total characters: {stats.char_total}")
            logger.info(f"[{request_id}] Estimated tokens: {stats.token_estimate}")
            logger.info(f"[{request_id}] User/External ratio: {stats.user_external_ratio:.2%}")
            logger.info(f"[{request_id}] File chunks: {stats.file_chunks_count}")
            logger.info(f"[{request_id}] Extracted file chars: {stats.extracted_total_chars}")
            
            # Step 7: Package payload
            step_start = time.time()
            total_time = (time.time() - start_time) * 1000
            
            prepared = package_payload(
                normalized_user=normalized_user,
                normalized_external=normalized_external,
                emoji_descriptions=user_emoji_descs,
                hmacs=hmacs,
                stats=stats,
                image_dict={},  # No image for text endpoint
                emoji_summary=emoji_summary,
                request_id=request_id,
                rag_enabled=rag_enabled,
                has_media=False,
                has_file=bool(file_chunks),
                file_info=file_info,
                prep_time_ms=total_time,
                step_times=step_times
            )
            step_times["packaging"] = (time.time() - step_start) * 1000
            
            # DETAILED LOG: Show final payload
            logger.info(f"[{request_id}] ===== STEP 6: PAYLOAD PACKAGING =====")
            logger.info(f"[{request_id}] PreparedInput structure created:")
            logger.info(f"[{request_id}]   text_embed_stub:")
            logger.info(f"[{request_id}]     - normalized_user: {len(prepared.text_embed_stub.normalized_user)} chars")
            logger.info(f"[{request_id}]     - normalized_external: {len(prepared.text_embed_stub.normalized_external)} chunks")
            logger.info(f"[{request_id}]     - hmacs: {len(prepared.text_embed_stub.hmacs)} signatures")
            logger.info(f"[{request_id}]     - emoji_descriptions: {len(prepared.text_embed_stub.emoji_descriptions)}")
            logger.info(f"[{request_id}]   image_emoji_stub:")
            logger.info(f"[{request_id}]     - emoji_summary.count: {prepared.image_emoji_stub.emoji_summary.count}")
            logger.info(f"[{request_id}]   metadata:")
            logger.info(f"[{request_id}]     - request_id: {prepared.metadata.request_id}")
            logger.info(f"[{request_id}]     - rag_enabled: {prepared.metadata.rag_enabled}")
            logger.info(f"[{request_id}]     - has_file: {prepared.metadata.has_file}")
            logger.info(f"[{request_id}]     - prep_time_ms: {prepared.metadata.prep_time_ms:.2f}")
            
            # Validate payload
            valid_payload, payload_error = validate_payload(prepared)
            if not valid_payload:
                logger.error(f"Payload validation failed: {payload_error}")
                raise HTTPException(status_code=500, detail=f"Payload validation failed: {payload_error}")
            
            logger.info(f"[{request_id}] ✓ Payload validation: PASSED")
            
            # Save output to disk
            output_saver = get_output_saver()
            saved_path = output_saver.save_layer0_output(prepared)
            if saved_path:
                logger.info(f"[{request_id}] ✓ Output saved to: {saved_path}")
            
            # Log summary
            logger.info(f"[{request_id}] ===== PREPARATION COMPLETE =====")
            logger.info(summarize_payload(prepared))
            logger.info(f"[{request_id}] → Ready to send to /api/v1/generate endpoint")
            
            # Cleanup temp file
            if temp_file_path and os.path.exists(temp_file_path):
                try:
                    os.remove(temp_file_path)
                except Exception as e:
                    logger.warning(f"Failed to cleanup temp file: {e}")
            
            return prepared
    
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Error processing request: {e}", exc_info=True)
        total_time = (time.time() - start_time) * 1000
        return create_error_response(str(e), prep_time_ms=total_time)


@app.post(
    f"{settings.API_PREFIX}/prepare-media",
    response_model=PreparedInput,
    status_code=status.HTTP_200_OK,
    summary="Prepare media input for image/emoji processing",
    description=(
        "Accepts text with images and emojis. "
        "Processes media metadata and returns data ready for "
        "specialized image/emoji analysis layers."
    )
)
async def prepare_media_input(
    user_prompt: str = Form(..., description="User's input text"),
    image: Optional[UploadFile] = File(None, description="Optional image upload"),
    image_path: Optional[str] = Form(None, description="Optional path to image on server")
):
    """
    Prepare media input (images and emojis).
    
    Steps:
    1. Parse and validate input
    2. Process image metadata
    3. Extract and process emojis
    4. Package payload
    """
    start_time = time.time()
    step_times = {}
    
    try:
        # Step 1: Parse and validate
        step_start = time.time()
        
        valid, error = validate_request(user_prompt)
        if not valid:
            raise HTTPException(status_code=400, detail=error)
        
        # Handle image upload
        temp_image_path = None
        if image:
            filename = image.filename
            temp_image_path = str(settings.get_file_path(filename))
            
            with open(temp_image_path, "wb") as f:
                content = await image.read()
                f.write(content)
            
            logger.info(f"Image uploaded: {filename} ({len(content)} bytes)")
            image_path = temp_image_path
        
        parsed = parse_and_validate(
            user_prompt=user_prompt,
            image_path=image_path
        )
        
        request_id = parsed["request_id"]
        step_times["parse_validate"] = (time.time() - step_start) * 1000
        
        with RequestLogger(request_id, logger) as req_logger:
            # Step 2: Normalize text and extract emojis
            step_start = time.time()
            normalized_user, user_emojis, user_emoji_descs = normalize_text(
                parsed["raw_user"],
                preserve_emojis=True
            )
            step_times["normalization"] = (time.time() - step_start) * 1000
            req_logger.log_step("normalization", step_times["normalization"])
            
            # Step 3: Process media
            step_start = time.time()
            image_dict, emoji_summary = process_media(
                image_path=parsed["raw_image"] if parsed["validation"]["image_valid"] else None,
                emojis=user_emojis,
                emoji_descriptions=user_emoji_descs
            )
            step_times["media_processing"] = (time.time() - step_start) * 1000
            req_logger.log_step("media_processing", step_times["media_processing"])
            
            # Step 4: Calculate stats (minimal for media endpoint)
            step_start = time.time()
            stats = calculate_tokens_and_stats(
                user_text=normalized_user,
                external_chunks=[],
                file_chunks_count=0,
                extracted_total_chars=0
            )
            step_times["token_calculation"] = (time.time() - step_start) * 1000
            
            # Step 5: Package payload
            step_start = time.time()
            total_time = (time.time() - start_time) * 1000
            
            prepared = package_payload(
                normalized_user=normalized_user,
                normalized_external=[],
                emoji_descriptions=user_emoji_descs,
                hmacs=[],
                stats=stats,
                image_dict=image_dict,
                emoji_summary=emoji_summary,
                request_id=request_id,
                rag_enabled=False,
                has_media=bool(image_dict and "error" not in image_dict),
                has_file=False,
                file_info=None,
                prep_time_ms=total_time,
                step_times=step_times
            )
            step_times["packaging"] = (time.time() - step_start) * 1000
            
            # Validate payload
            valid_payload, payload_error = validate_payload(prepared)
            if not valid_payload:
                logger.error(f"Payload validation failed: {payload_error}")
                raise HTTPException(status_code=500, detail=f"Payload validation failed: {payload_error}")
            
            # Save output to disk
            output_saver = get_output_saver()
            saved_path = output_saver.save_media_output(prepared)
            if saved_path:
                logger.info(f"[{request_id}] ✓ Output saved to: {saved_path}")
            
            # Log summary
            logger.info(summarize_payload(prepared))
            
            # Cleanup temp file
            if temp_image_path and os.path.exists(temp_image_path):
                try:
                    os.remove(temp_image_path)
                except Exception as e:
                    logger.warning(f"Failed to cleanup temp image: {e}")
            
            return prepared
    
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Error processing media request: {e}", exc_info=True)
        total_time = (time.time() - start_time) * 1000
        return create_error_response(str(e), prep_time_ms=total_time)


@app.get("/", response_class=HTMLResponse)
async def root():
    """Serve the web interface."""
    try:
        from pathlib import Path
        html_path = Path(__file__).parent / "static" / "index.html"
        if html_path.exists():
            return html_path.read_text()
        else:
            return """
            <html>
                <body>
                    <h1>LLM-Protect Input Preparation API</h1>
                    <p>Version: {}</p>
                    <ul>
                        <li><a href="/docs">API Documentation</a></li>
                        <li><a href="/health">Health Check</a></li>
                    </ul>
                </body>
            </html>
            """.format(settings.API_VERSION)
    except Exception as e:
        logger.error(f"Error serving root: {e}")
        return HTMLResponse(f"<h1>Error: {e}</h1>", status_code=500)


@app.post(
    f"{settings.API_PREFIX}/generate",
    response_model=GenerateResponse,
    status_code=status.HTTP_200_OK,
    summary="Generate LLM response from prepared input",
    description=(
        "Takes prepared input from /prepare-text endpoint and generates "
        "a response using Gemma 2B. This endpoint receives the HMAC-verified "
        "and processed input data and runs it through the LLM."
    )
)
async def generate_llm_response(request: GenerateRequest):
    """
    Generate LLM response from prepared input.
    
    This endpoint receives the output from /prepare-text and uses it to
    generate a response with the Gemma 2B model.
    """
    start_time = time.time()
    
    try:
        # Extract the prepared data
        prepared = request.prepared_input
        
        # Construct the prompt from prepared data
        # Combine user input with external data context
        prompt_parts = [prepared.text_embed_stub.normalized_user]
        
        if prepared.text_embed_stub.normalized_external:
            prompt_parts.append("\n\nContext:")
            for chunk in prepared.text_embed_stub.normalized_external:
                # Remove delimiters for the prompt
                clean_chunk = chunk.replace("[EXTERNAL]", "").replace("[/EXTERNAL]", "")
                prompt_parts.append(f"- {clean_chunk}")
        
        full_prompt = "\n".join(prompt_parts)
        
        logger.info(
            f"[{prepared.metadata.request_id}] ===== LLM GENERATION STARTED ====="
        )
        logger.info(
            f"[{prepared.metadata.request_id}] Prompt construction:"
        )
        logger.info(
            f"[{prepared.metadata.request_id}]   User text: {len(prepared.text_embed_stub.normalized_user)} chars"
        )
        logger.info(
            f"[{prepared.metadata.request_id}]   External chunks: {len(prepared.text_embed_stub.normalized_external)}"
        )
        logger.info(
            f"[{prepared.metadata.request_id}]   Full prompt length: {len(full_prompt)} chars"
        )
        logger.info(
            f"[{prepared.metadata.request_id}]   Estimated tokens: {prepared.text_embed_stub.stats.token_estimate}"
        )
        logger.info(
            f"[{prepared.metadata.request_id}] Full prompt preview:"
        )
        logger.info(f"[{prepared.metadata.request_id}] {full_prompt[:200]}..." if len(full_prompt) > 200 else f"[{prepared.metadata.request_id}] {full_prompt}")
        
        # Generate response
        result = generate_response(
            prompt=full_prompt,
            max_new_tokens=request.max_new_tokens,
            temperature=request.temperature,
            top_p=request.top_p,
            do_sample=request.do_sample
        )
        
        # Add preparation metadata
        result["preparation_metadata"] = {
            "request_id": prepared.metadata.request_id,
            "prep_time_ms": prepared.metadata.prep_time_ms,
            "input_tokens_estimated": prepared.text_embed_stub.stats.token_estimate,
            "rag_chunks": len(prepared.text_embed_stub.normalized_external),
            "hmac_signatures": len(prepared.text_embed_stub.hmacs),
        }
        
        total_time = (time.time() - start_time) * 1000
        
        # DETAILED LOG: Show generation results
        logger.info(f"[{prepared.metadata.request_id}] ===== LLM GENERATION COMPLETE =====")
        logger.info(f"[{prepared.metadata.request_id}] Success: {result.get('success', False)}")
        logger.info(f"[{prepared.metadata.request_id}] Input tokens (actual): {result.get('input_tokens', 0)}")
        logger.info(f"[{prepared.metadata.request_id}] Output tokens: {result.get('output_tokens', 0)}")
        logger.info(f"[{prepared.metadata.request_id}] Generation time: {result.get('total_time_ms', 0):.2f}ms")
        logger.info(f"[{prepared.metadata.request_id}] Total time (prep + gen): {total_time:.2f}ms")
        if result.get('success'):
            generated = result.get('generated_text', '')
            logger.info(f"[{prepared.metadata.request_id}] Generated text preview: {generated[:150]}..." if len(generated) > 150 else f"[{prepared.metadata.request_id}] Generated text: {generated}")
        else:
            logger.error(f"[{prepared.metadata.request_id}] Generation error: {result.get('error', 'Unknown')}")
        
        logger.info(f"[{prepared.metadata.request_id}] ===== PIPELINE COMPLETE =====")
        
        return GenerateResponse(**result)
        
    except Exception as e:
        logger.error(f"Error generating response: {e}", exc_info=True)
        return GenerateResponse(
            success=False,
            generated_text="",
            input_tokens=0,
            output_tokens=0,
            total_time_ms=(time.time() - start_time) * 1000,
            error=str(e)
        )


@app.get(f"{settings.API_PREFIX}/model-status")
async def model_status():
    """
    Check the status of the LLM model.
    
    Returns information about whether the model is loaded and available.
    """
    status_info = check_model_availability()
    return {
        "model": "gemma-2b",
        **status_info,
        "endpoint": f"{settings.API_PREFIX}/generate"
    }


@app.get(f"{settings.API_PREFIX}/output-stats")
async def output_statistics():
    """
    Get statistics about saved outputs.
    
    Returns counts and locations of saved Layer 0 and media outputs.
    """
    output_saver = get_output_saver()
    stats = output_saver.get_output_stats()
    
    # Add recent files info
    recent_layer0 = output_saver.get_recent_outputs("layer0", limit=5)
    recent_media = output_saver.get_recent_outputs("media", limit=5)
    
    stats["recent_layer0_files"] = [f.name for f in recent_layer0]
    stats["recent_media_files"] = [f.name for f in recent_media]
    
    return stats


if __name__ == "__main__":
    import uvicorn
    
    uvicorn.run(
        "app.main:app",
        host=settings.API_HOST,
        port=settings.API_PORT,
        reload=True,
        log_level=settings.LOG_LEVEL.lower()
    )

